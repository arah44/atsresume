# Job Scraper - Clean & Simple

## Overview

A streamlined job scraper that tries Cheerio first (direct HTTP), then falls back to Jina.ai if needed. No external APIs required.

## Architecture

```
JobScraper
â”œâ”€â”€ tryCheerio()     â†’ Direct HTTP with browser headers
â”œâ”€â”€ tryJina()        â†’ Jina.ai proxy as fallback
â””â”€â”€ parseJobData()   â†’ LangChain AI extraction
```

**Simple. No providers. No wrappers. Just works.**

## Features

âœ… **Cheerio First**: Direct HTTP requests with realistic browser headers
âœ… **Jina Fallback**: Automatic fallback to Jina.ai proxy service
âœ… **AI Extraction**: LangChain-powered intelligent job data parsing
âœ… **Smart Errors**: Helpful error messages with actionable advice
âœ… **Parallel Scraping**: Batch process multiple URLs efficiently

## Usage

### Single Job
```typescript
import { JobScraper } from '@/lib/scraper';

const result = await JobScraper.scrapeJob('https://example.com/job/123');

if (result.success) {
  console.log(result.job.name);        // Job title
  console.log(result.job.company);     // Company name
  console.log(result.job.description); // Full description
}
```

### Multiple Jobs
```typescript
const urls = [
  'https://example.com/job/1',
  'https://example.com/job/2'
];

const results = await JobScraper.scrapeMultipleJobs(urls);
```

### API Endpoint
```bash
POST /api/scrape
{
  "urls": ["https://example.com/job/123"]
}
```

## What Gets Extracted

The AI extracts:
- ğŸ“Œ Job title
- ğŸ¢ Company name
- ğŸ“ Full description
- ğŸ  Remote work status
- ğŸ”— Apply URL (if available)
- âš¡ Easy apply flag (if available)

## Supported Sites

- âœ… Indeed
- âœ… Glassdoor
- âœ… Monster
- âœ… ZipRecruiter
- âœ… Dice
- âœ… Wellfound (AngelList)
- âœ… Greenhouse ATS
- âœ… Lever ATS
- âœ… Company career pages
- âš ï¸  LinkedIn (requires manual copy-paste due to anti-bot measures)

## Error Handling

### LinkedIn (HTTP 451)
```
LinkedIn blocks automated scraping.
â†’ Copy the job content manually
â†’ Paste into "Raw Job Content" field
â†’ AI will extract everything
```

### Other Blocks (HTTP 403)
```
Site is blocking scrapers.
â†’ Try copying content manually
```

## File Structure

```
src/lib/scraper/
â”œâ”€â”€ job-scraper.ts          â†’ Main scraper with Cheerio + Jina
â”œâ”€â”€ cheerio-scraper.ts      â†’ Direct HTTP scraper
â”œâ”€â”€ base-scraper.ts         â†’ Base class (rate limiting, retries, etc.)
â”œâ”€â”€ scraper-provider.ts     â†’ Simple provider interface
â””â”€â”€ index.ts                â†’ Exports
```

## Testing

```bash
# Test the scraper
bun run test:scraper

# Test AI extraction
bun run scripts/langchain/test-job-data-extraction.ts
```

## Environment Variables

```bash
# Required for AI extraction
OPENROUTER_API_KEY=your_key_here
```

## How It Works

1. **Try Cheerio**
   - Direct HTTP fetch with browser headers
   - Rate limited (1 req/sec with randomization)
   - 2 retries with exponential backoff

2. **Fallback to Jina**
   - If Cheerio fails, try Jina.ai proxy
   - Uses `https://r.jina.ai/` prefix
   - 30 second timeout

3. **AI Extraction**
   - LangChain parses the HTML
   - Structured output via Zod schema
   - Falls back to regex if AI fails

## Benefits Over Old Architecture

| Before | After |
|--------|-------|
| âŒ Multiple provider wrappers | âœ… Single JobScraper class |
| âŒ Complex inheritance | âœ… Simple composition |
| âŒ GhostGenius dependency | âœ… No external APIs needed |
| âŒ Confusing file structure | âœ… Clean, flat structure |
| âŒ Hard to debug | âœ… Clear flow, better errors |

## Notes

- **No external job APIs required** - everything is self-contained
- **Rate limiting built-in** - respects target sites
- **Smart user-agent rotation** - appears more human-like
- **Automatic retries** - handles transient failures
- **LinkedIn workaround** - manual copy-paste with AI extraction

---

**Simple. Reliable. Self-contained.**

